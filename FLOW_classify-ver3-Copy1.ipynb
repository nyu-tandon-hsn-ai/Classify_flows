{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = np.asarray(df[name], dtype = np.float).mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = np.asarray(df[name], dtype = np.float).std()\n",
    "\n",
    "    df[name] = (np.asarray(df[name], dtype = np.float) - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read df_ 3492 rows.\n",
      "Read df_test 1497 rows.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "\n",
    "df_ = pd.read_csv(\"./train_70%_v3.csv\")\n",
    "df_test = pd.read_csv(\"./test_30%_v3.csv\")\n",
    "print(\"Read df_ {} rows.\".format(len(df_)))\n",
    "print(\"Read df_test {} rows.\".format(len(df_test)))\n",
    "#print(\"Read {} rows.\".format(len(df1)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "df_ = df_.drop([df_.columns[0], df_.columns[8], df_.columns[9], df_.columns[10]], axis=1)\n",
    "df_test = df_test.drop([df_test.columns[0], df_test.columns[8], df_test.columns[9], df_test.columns[10]], axis=1)\n",
    "\n",
    "df_.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "df_test.dropna(inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(pkt_len)</th>\n",
       "      <th>stddev(pkt_len)</th>\n",
       "      <th>fb_ratio</th>\n",
       "      <th>inter_arrival_time</th>\n",
       "      <th>pkt_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>is_tcp</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>28.867513</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>133.080407</td>\n",
       "      <td>4</td>\n",
       "      <td>399.241220</td>\n",
       "      <td>0</td>\n",
       "      <td>voip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195.933333</td>\n",
       "      <td>371.472834</td>\n",
       "      <td>0.271744</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>15</td>\n",
       "      <td>0.260353</td>\n",
       "      <td>1</td>\n",
       "      <td>voip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1310.382500</td>\n",
       "      <td>115.900593</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>800</td>\n",
       "      <td>1.778840</td>\n",
       "      <td>1</td>\n",
       "      <td>streaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>33.941125</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>1</td>\n",
       "      <td>voip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205.357143</td>\n",
       "      <td>383.630352</td>\n",
       "      <td>0.279484</td>\n",
       "      <td>0.061708</td>\n",
       "      <td>14</td>\n",
       "      <td>0.802204</td>\n",
       "      <td>1</td>\n",
       "      <td>voip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(pkt_len)  stddev(pkt_len)  fb_ratio  inter_arrival_time  pkt_count  \\\n",
       "0     83.000000        28.867513  0.537037          133.080407          4   \n",
       "1    195.933333       371.472834  0.271744            0.018597         15   \n",
       "2   1310.382500       115.900593 -1.000000            0.002226        800   \n",
       "3     64.000000        33.941125  2.200000            0.025113          2   \n",
       "4    205.357143       383.630352  0.279484            0.061708         14   \n",
       "\n",
       "     duration  is_tcp    outcome  \n",
       "0  399.241220       0       voip  \n",
       "1    0.260353       1       voip  \n",
       "2    1.778840       1  streaming  \n",
       "3    0.025113       1       voip  \n",
       "4    0.802204       1       voip  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(pkt_len)</th>\n",
       "      <th>stddev(pkt_len)</th>\n",
       "      <th>fb_ratio</th>\n",
       "      <th>inter_arrival_time</th>\n",
       "      <th>pkt_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>is_tcp</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316.384615</td>\n",
       "      <td>455.087075</td>\n",
       "      <td>0.751331</td>\n",
       "      <td>0.018904</td>\n",
       "      <td>26</td>\n",
       "      <td>0.472603</td>\n",
       "      <td>1</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347.591837</td>\n",
       "      <td>480.886028</td>\n",
       "      <td>0.359840</td>\n",
       "      <td>0.181995</td>\n",
       "      <td>49</td>\n",
       "      <td>8.735755</td>\n",
       "      <td>1</td>\n",
       "      <td>streaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.200000</td>\n",
       "      <td>20.571825</td>\n",
       "      <td>1.859375</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>5</td>\n",
       "      <td>0.069894</td>\n",
       "      <td>1</td>\n",
       "      <td>download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>415.550000</td>\n",
       "      <td>584.567989</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.016808</td>\n",
       "      <td>20</td>\n",
       "      <td>0.319353</td>\n",
       "      <td>1</td>\n",
       "      <td>download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1303.050995</td>\n",
       "      <td>129.033503</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>804</td>\n",
       "      <td>2.099729</td>\n",
       "      <td>1</td>\n",
       "      <td>streaming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(pkt_len)  stddev(pkt_len)  fb_ratio  inter_arrival_time  pkt_count  \\\n",
       "0    316.384615       455.087075  0.751331            0.018904         26   \n",
       "1    347.591837       480.886028  0.359840            0.181995         49   \n",
       "2     73.200000        20.571825  1.859375            0.017474          5   \n",
       "3    415.550000       584.567989  0.100503            0.016808         20   \n",
       "4   1303.050995       129.033503 -1.000000            0.002615        804   \n",
       "\n",
       "   duration  is_tcp    outcome  \n",
       "0  0.472603       1       game  \n",
       "1  8.735755       1  streaming  \n",
       "2  0.069894       1   download  \n",
       "3  0.319353       1   download  \n",
       "4  2.099729       1  streaming  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['download', 'game', 'streaming', 'voip'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_numeric_zscore(df_, 'fb_ratio')\n",
    "encode_numeric_zscore(df_, 'pkt_count')\n",
    "encode_numeric_zscore(df_, 'inter_arrival_time')\n",
    "encode_numeric_zscore(df_, 'stddev(pkt_len)')\n",
    "encode_numeric_zscore(df_, 'avg(pkt_len)')\n",
    "# encode_numeric_zscore(df_, 'pkt_len')\n",
    "encode_numeric_zscore(df_, 'duration')\n",
    "encode_text_index(df_, 'outcome')\n",
    "\n",
    "encode_numeric_zscore(df_test, 'fb_ratio')\n",
    "encode_numeric_zscore(df_test, 'pkt_count')\n",
    "encode_numeric_zscore(df_test, 'inter_arrival_time')\n",
    "encode_numeric_zscore(df_test, 'stddev(pkt_len)')\n",
    "encode_numeric_zscore(df_test, 'avg(pkt_len)')\n",
    "# encode_numeric_zscore(df_test, 'pkt_len')\n",
    "encode_numeric_zscore(df_test, 'duration')\n",
    "encode_text_index(df_test, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = to_xy(df_, 'outcome')\n",
    "x_test, y_test = to_xy(df_test, 'outcome')\n",
    "# x, y = to_xy(df_, ' Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(pkt_len)</th>\n",
       "      <th>stddev(pkt_len)</th>\n",
       "      <th>fb_ratio</th>\n",
       "      <th>inter_arrival_time</th>\n",
       "      <th>pkt_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>is_tcp</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.752548</td>\n",
       "      <td>-1.172816</td>\n",
       "      <td>0.117636</td>\n",
       "      <td>3.971602</td>\n",
       "      <td>-0.315017</td>\n",
       "      <td>2.746229</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.478117</td>\n",
       "      <td>0.520962</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>-0.081796</td>\n",
       "      <td>-0.303750</td>\n",
       "      <td>-0.191508</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.230023</td>\n",
       "      <td>-0.742540</td>\n",
       "      <td>-0.410789</td>\n",
       "      <td>-0.082295</td>\n",
       "      <td>0.500312</td>\n",
       "      <td>-0.180327</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.798719</td>\n",
       "      <td>-1.147733</td>\n",
       "      <td>0.689354</td>\n",
       "      <td>-0.081598</td>\n",
       "      <td>-0.317066</td>\n",
       "      <td>-0.193240</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.455217</td>\n",
       "      <td>0.581067</td>\n",
       "      <td>0.029091</td>\n",
       "      <td>-0.080483</td>\n",
       "      <td>-0.304775</td>\n",
       "      <td>-0.187518</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(pkt_len)  stddev(pkt_len)  fb_ratio  inter_arrival_time  pkt_count  \\\n",
       "0     -0.752548        -1.172816  0.117636            3.971602  -0.315017   \n",
       "1     -0.478117         0.520962  0.026430           -0.081796  -0.303750   \n",
       "2      2.230023        -0.742540 -0.410789           -0.082295   0.500312   \n",
       "3     -0.798719        -1.147733  0.689354           -0.081598  -0.317066   \n",
       "4     -0.455217         0.581067  0.029091           -0.080483  -0.304775   \n",
       "\n",
       "   duration  is_tcp  outcome  \n",
       "0  2.746229       0        3  \n",
       "1 -0.191508       1        3  \n",
       "2 -0.180327       1        2  \n",
       "3 -0.193240       1        3  \n",
       "4 -0.187518       1        3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create neural net\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(y_train.shape[1],activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 196\n",
      "Trainable params: 196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # TODO:  Create two empty lists, self.loss and self.val_acc\n",
    "        self.losses = []\n",
    "        self.accs = []\n",
    "        self.val_acc = []\n",
    "        self.val_loss = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        # TODO:  This is called at the end of each batch.  \n",
    "        # Add the loss in logs.get('loss') to the loss list\n",
    "        loss = logs.get('loss')\n",
    "        acc = logs.get('acc')\n",
    "        self.losses.append(loss)\n",
    "        self.accs.append(acc)\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # TODO:  This is called at the end of each epoch.  \n",
    "        # Add the test accuracy in logs.get('loss') to the val_acc list\n",
    "        val_acc = logs.get('val_acc')\n",
    "        val_loss = logs.get('val_loss')\n",
    "        self.val_acc.append(val_acc)\n",
    "        self.val_loss.append(val_loss)\n",
    "\n",
    "# Create an instance of the history callback\n",
    "history_cb = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3492 samples, validate on 1497 samples\n",
      "Epoch 1/300\n",
      "3492/3492 [==============================] - 0s - loss: 1.2613 - acc: 0.6973 - val_loss: 1.0837 - val_acc: 0.7395\n",
      "Epoch 2/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.9843 - acc: 0.7159 - val_loss: 0.8646 - val_acc: 0.7388\n",
      "Epoch 3/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.8913 - acc: 0.7162 - val_loss: 0.8169 - val_acc: 0.7388\n",
      "Epoch 4/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.8502 - acc: 0.7162 - val_loss: 0.7870 - val_acc: 0.7388\n",
      "Epoch 5/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.8218 - acc: 0.7162 - val_loss: 0.7739 - val_acc: 0.7381\n",
      "Epoch 6/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.8033 - acc: 0.7188 - val_loss: 0.7607 - val_acc: 0.7388\n",
      "Epoch 7/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7903 - acc: 0.7168 - val_loss: 0.7568 - val_acc: 0.7428\n",
      "Epoch 8/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7806 - acc: 0.7165 - val_loss: 0.7503 - val_acc: 0.7428\n",
      "Epoch 9/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7729 - acc: 0.7171 - val_loss: 0.7465 - val_acc: 0.7428\n",
      "Epoch 10/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7655 - acc: 0.7148 - val_loss: 0.7393 - val_acc: 0.7422\n",
      "Epoch 11/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7592 - acc: 0.7148 - val_loss: 0.7359 - val_acc: 0.7415\n",
      "Epoch 12/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7521 - acc: 0.7176 - val_loss: 0.7286 - val_acc: 0.7428\n",
      "Epoch 13/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7450 - acc: 0.7188 - val_loss: 0.7246 - val_acc: 0.7455\n",
      "Epoch 14/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7395 - acc: 0.7136 - val_loss: 0.7206 - val_acc: 0.7462\n",
      "Epoch 15/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7340 - acc: 0.7133 - val_loss: 0.7176 - val_acc: 0.7442\n",
      "Epoch 16/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7292 - acc: 0.7168 - val_loss: 0.7151 - val_acc: 0.7455\n",
      "Epoch 17/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7245 - acc: 0.7194 - val_loss: 0.7113 - val_acc: 0.7455\n",
      "Epoch 18/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7209 - acc: 0.7205 - val_loss: 0.7113 - val_acc: 0.7502\n",
      "Epoch 19/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7168 - acc: 0.7205 - val_loss: 0.7131 - val_acc: 0.7502\n",
      "Epoch 20/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7131 - acc: 0.7285 - val_loss: 0.7079 - val_acc: 0.7515\n",
      "Epoch 21/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7099 - acc: 0.7228 - val_loss: 0.7055 - val_acc: 0.7488\n",
      "Epoch 22/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7067 - acc: 0.7274 - val_loss: 0.7028 - val_acc: 0.7475\n",
      "Epoch 23/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7036 - acc: 0.7288 - val_loss: 0.7018 - val_acc: 0.7515\n",
      "Epoch 24/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.7010 - acc: 0.7308 - val_loss: 0.7013 - val_acc: 0.7615\n",
      "Epoch 25/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6980 - acc: 0.7337 - val_loss: 0.6999 - val_acc: 0.7609\n",
      "Epoch 26/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6957 - acc: 0.7325 - val_loss: 0.6989 - val_acc: 0.7582\n",
      "Epoch 27/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6930 - acc: 0.7354 - val_loss: 0.6985 - val_acc: 0.7595\n",
      "Epoch 28/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6908 - acc: 0.7345 - val_loss: 0.6962 - val_acc: 0.7622\n",
      "Epoch 29/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6880 - acc: 0.7368 - val_loss: 0.6964 - val_acc: 0.7548\n",
      "Epoch 30/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6859 - acc: 0.7391 - val_loss: 0.6945 - val_acc: 0.7555\n",
      "Epoch 31/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6834 - acc: 0.7443 - val_loss: 0.6933 - val_acc: 0.7562\n",
      "Epoch 32/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6802 - acc: 0.7534 - val_loss: 0.6918 - val_acc: 0.7635\n",
      "Epoch 33/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6778 - acc: 0.7592 - val_loss: 0.6889 - val_acc: 0.7562\n",
      "Epoch 34/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6749 - acc: 0.7574 - val_loss: 0.6920 - val_acc: 0.7542\n",
      "Epoch 35/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6733 - acc: 0.7600 - val_loss: 0.6873 - val_acc: 0.7455\n",
      "Epoch 36/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6709 - acc: 0.7600 - val_loss: 0.6881 - val_acc: 0.7555\n",
      "Epoch 37/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6692 - acc: 0.7626 - val_loss: 0.6886 - val_acc: 0.7455\n",
      "Epoch 38/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6674 - acc: 0.7615 - val_loss: 0.6864 - val_acc: 0.7475\n",
      "Epoch 39/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6656 - acc: 0.7563 - val_loss: 0.6873 - val_acc: 0.7455\n",
      "Epoch 40/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6635 - acc: 0.7615 - val_loss: 0.6870 - val_acc: 0.7475\n",
      "Epoch 41/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6619 - acc: 0.7577 - val_loss: 0.6844 - val_acc: 0.7448\n",
      "Epoch 42/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6591 - acc: 0.7569 - val_loss: 0.6831 - val_acc: 0.7535\n",
      "Epoch 43/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6574 - acc: 0.7629 - val_loss: 0.6863 - val_acc: 0.7535\n",
      "Epoch 44/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6549 - acc: 0.7609 - val_loss: 0.6859 - val_acc: 0.7568\n",
      "Epoch 45/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6541 - acc: 0.7655 - val_loss: 0.6822 - val_acc: 0.7542\n",
      "Epoch 46/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6516 - acc: 0.7612 - val_loss: 0.6820 - val_acc: 0.7542\n",
      "Epoch 47/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6492 - acc: 0.7595 - val_loss: 0.6811 - val_acc: 0.7548\n",
      "Epoch 48/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6481 - acc: 0.7620 - val_loss: 0.6832 - val_acc: 0.7562\n",
      "Epoch 49/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6468 - acc: 0.7620 - val_loss: 0.6819 - val_acc: 0.7542\n",
      "Epoch 50/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6446 - acc: 0.7620 - val_loss: 0.6811 - val_acc: 0.7548\n",
      "Epoch 51/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6437 - acc: 0.7603 - val_loss: 0.6808 - val_acc: 0.7555\n",
      "Epoch 52/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6417 - acc: 0.7617 - val_loss: 0.6799 - val_acc: 0.7542\n",
      "Epoch 53/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6402 - acc: 0.7646 - val_loss: 0.6816 - val_acc: 0.7542\n",
      "Epoch 54/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6385 - acc: 0.7606 - val_loss: 0.6832 - val_acc: 0.7548\n",
      "Epoch 55/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6379 - acc: 0.7609 - val_loss: 0.6818 - val_acc: 0.7535\n",
      "Epoch 56/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6361 - acc: 0.7626 - val_loss: 0.6861 - val_acc: 0.7542\n",
      "Epoch 57/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6348 - acc: 0.7695 - val_loss: 0.6896 - val_acc: 0.7542\n",
      "Epoch 58/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6333 - acc: 0.7603 - val_loss: 0.6887 - val_acc: 0.7555\n",
      "Epoch 59/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6328 - acc: 0.7623 - val_loss: 0.6869 - val_acc: 0.7542\n",
      "Epoch 60/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6310 - acc: 0.7663 - val_loss: 0.6885 - val_acc: 0.7535\n",
      "Epoch 61/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6303 - acc: 0.7663 - val_loss: 0.6906 - val_acc: 0.7535\n",
      "Epoch 62/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6283 - acc: 0.7660 - val_loss: 0.6966 - val_acc: 0.7528\n",
      "Epoch 63/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6279 - acc: 0.7658 - val_loss: 0.6955 - val_acc: 0.7522\n",
      "Epoch 64/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6256 - acc: 0.7675 - val_loss: 0.6958 - val_acc: 0.7542\n",
      "Epoch 65/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6264 - acc: 0.7646 - val_loss: 0.6990 - val_acc: 0.7522\n",
      "Epoch 66/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6242 - acc: 0.7652 - val_loss: 0.7037 - val_acc: 0.7542\n",
      "Epoch 67/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6230 - acc: 0.7692 - val_loss: 0.6995 - val_acc: 0.7468\n",
      "Epoch 68/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6224 - acc: 0.7678 - val_loss: 0.6991 - val_acc: 0.7535\n",
      "Epoch 69/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6210 - acc: 0.7680 - val_loss: 0.7037 - val_acc: 0.7555\n",
      "Epoch 70/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6196 - acc: 0.7695 - val_loss: 0.7036 - val_acc: 0.7522\n",
      "Epoch 71/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6179 - acc: 0.7698 - val_loss: 0.7116 - val_acc: 0.7555\n",
      "Epoch 72/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6178 - acc: 0.7666 - val_loss: 0.7063 - val_acc: 0.7548\n",
      "Epoch 73/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6163 - acc: 0.7706 - val_loss: 0.7107 - val_acc: 0.7455\n",
      "Epoch 74/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6159 - acc: 0.7678 - val_loss: 0.7117 - val_acc: 0.7468\n",
      "Epoch 75/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6148 - acc: 0.7712 - val_loss: 0.7114 - val_acc: 0.7482\n",
      "Epoch 76/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6135 - acc: 0.7706 - val_loss: 0.7140 - val_acc: 0.7475\n",
      "Epoch 77/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6124 - acc: 0.7700 - val_loss: 0.7182 - val_acc: 0.7448\n",
      "Epoch 78/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6121 - acc: 0.7715 - val_loss: 0.7228 - val_acc: 0.7495\n",
      "Epoch 79/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6109 - acc: 0.7721 - val_loss: 0.7270 - val_acc: 0.7495\n",
      "Epoch 80/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6101 - acc: 0.7706 - val_loss: 0.7272 - val_acc: 0.7495\n",
      "Epoch 81/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6094 - acc: 0.7712 - val_loss: 0.7257 - val_acc: 0.7502\n",
      "Epoch 82/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6081 - acc: 0.7712 - val_loss: 0.7278 - val_acc: 0.7462\n",
      "Epoch 83/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6075 - acc: 0.7712 - val_loss: 0.7309 - val_acc: 0.7582\n",
      "Epoch 84/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6067 - acc: 0.7715 - val_loss: 0.7373 - val_acc: 0.7555\n",
      "Epoch 85/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6051 - acc: 0.7703 - val_loss: 0.7366 - val_acc: 0.7595\n",
      "Epoch 86/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6054 - acc: 0.7715 - val_loss: 0.7433 - val_acc: 0.7602\n",
      "Epoch 87/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6046 - acc: 0.7718 - val_loss: 0.7468 - val_acc: 0.7542\n",
      "Epoch 88/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6032 - acc: 0.7718 - val_loss: 0.7478 - val_acc: 0.7542\n",
      "Epoch 89/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6037 - acc: 0.7709 - val_loss: 0.7488 - val_acc: 0.7562\n",
      "Epoch 90/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6027 - acc: 0.7712 - val_loss: 0.7543 - val_acc: 0.7555\n",
      "Epoch 91/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6023 - acc: 0.7741 - val_loss: 0.7562 - val_acc: 0.7542\n",
      "Epoch 92/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6012 - acc: 0.7729 - val_loss: 0.7567 - val_acc: 0.7548\n",
      "Epoch 93/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.6006 - acc: 0.7726 - val_loss: 0.7651 - val_acc: 0.7582\n",
      "Epoch 94/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5991 - acc: 0.7758 - val_loss: 0.7632 - val_acc: 0.7568\n",
      "Epoch 95/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5990 - acc: 0.7746 - val_loss: 0.7706 - val_acc: 0.75950.772\n",
      "Epoch 96/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5980 - acc: 0.7732 - val_loss: 0.7778 - val_acc: 0.7562\n",
      "Epoch 97/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5982 - acc: 0.7729 - val_loss: 0.7743 - val_acc: 0.7589\n",
      "Epoch 98/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5967 - acc: 0.7755 - val_loss: 0.7696 - val_acc: 0.7589\n",
      "Epoch 99/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5972 - acc: 0.7752 - val_loss: 0.7801 - val_acc: 0.7582\n",
      "Epoch 100/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5962 - acc: 0.7772 - val_loss: 0.7842 - val_acc: 0.7589\n",
      "Epoch 101/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5958 - acc: 0.7769 - val_loss: 0.7850 - val_acc: 0.7595\n",
      "Epoch 102/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5955 - acc: 0.7755 - val_loss: 0.7891 - val_acc: 0.7595\n",
      "Epoch 103/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5948 - acc: 0.7761 - val_loss: 0.7967 - val_acc: 0.7582\n",
      "Epoch 104/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5939 - acc: 0.7761 - val_loss: 0.7974 - val_acc: 0.7582\n",
      "Epoch 105/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5934 - acc: 0.7758 - val_loss: 0.7956 - val_acc: 0.7548\n",
      "Epoch 106/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5924 - acc: 0.7784 - val_loss: 0.8070 - val_acc: 0.7562\n",
      "Epoch 107/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5920 - acc: 0.7784 - val_loss: 0.7979 - val_acc: 0.7568\n",
      "Epoch 108/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5910 - acc: 0.7775 - val_loss: 0.8222 - val_acc: 0.7555\n",
      "Epoch 109/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5909 - acc: 0.7775 - val_loss: 0.8142 - val_acc: 0.7562\n",
      "Epoch 110/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5904 - acc: 0.7798 - val_loss: 0.8274 - val_acc: 0.7568\n",
      "Epoch 111/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5903 - acc: 0.7795 - val_loss: 0.8135 - val_acc: 0.7562\n",
      "Epoch 112/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5894 - acc: 0.7784 - val_loss: 0.8296 - val_acc: 0.7589\n",
      "Epoch 113/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5893 - acc: 0.7781 - val_loss: 0.8257 - val_acc: 0.7582\n",
      "Epoch 114/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5876 - acc: 0.7792 - val_loss: 0.8275 - val_acc: 0.7589\n",
      "Epoch 115/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5883 - acc: 0.7784 - val_loss: 0.8262 - val_acc: 0.7582\n",
      "Epoch 116/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5873 - acc: 0.7798 - val_loss: 0.8372 - val_acc: 0.7589\n",
      "Epoch 117/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5875 - acc: 0.7786 - val_loss: 0.8395 - val_acc: 0.7582\n",
      "Epoch 118/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5867 - acc: 0.7795 - val_loss: 0.8430 - val_acc: 0.7589\n",
      "Epoch 119/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5859 - acc: 0.7775 - val_loss: 0.8391 - val_acc: 0.7589\n",
      "Epoch 120/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5860 - acc: 0.7792 - val_loss: 0.8504 - val_acc: 0.7582\n",
      "Epoch 121/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5856 - acc: 0.7784 - val_loss: 0.8504 - val_acc: 0.7582\n",
      "Epoch 122/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5847 - acc: 0.7781 - val_loss: 0.8496 - val_acc: 0.7589\n",
      "Epoch 123/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5848 - acc: 0.7792 - val_loss: 0.8591 - val_acc: 0.7575\n",
      "Epoch 124/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5846 - acc: 0.7806 - val_loss: 0.8616 - val_acc: 0.7595\n",
      "Epoch 125/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5845 - acc: 0.7809 - val_loss: 0.8583 - val_acc: 0.7602\n",
      "Epoch 126/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5838 - acc: 0.7806 - val_loss: 0.8741 - val_acc: 0.7609\n",
      "Epoch 127/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5838 - acc: 0.7804 - val_loss: 0.8692 - val_acc: 0.7575\n",
      "Epoch 128/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5832 - acc: 0.7812 - val_loss: 0.8705 - val_acc: 0.7582\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492/3492 [==============================] - 0s - loss: 0.5815 - acc: 0.7806 - val_loss: 0.8793 - val_acc: 0.7622\n",
      "Epoch 130/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5822 - acc: 0.7801 - val_loss: 0.8740 - val_acc: 0.7602\n",
      "Epoch 131/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5818 - acc: 0.7815 - val_loss: 0.8790 - val_acc: 0.7615\n",
      "Epoch 132/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5809 - acc: 0.7821 - val_loss: 0.8914 - val_acc: 0.7609\n",
      "Epoch 133/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5805 - acc: 0.7818 - val_loss: 0.8880 - val_acc: 0.7609\n",
      "Epoch 134/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5805 - acc: 0.7838 - val_loss: 0.8979 - val_acc: 0.7595\n",
      "Epoch 135/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5794 - acc: 0.7818 - val_loss: 0.8983 - val_acc: 0.7602\n",
      "Epoch 136/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5798 - acc: 0.7818 - val_loss: 0.8967 - val_acc: 0.7609\n",
      "Epoch 137/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5783 - acc: 0.7847 - val_loss: 0.8993 - val_acc: 0.7609\n",
      "Epoch 138/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5787 - acc: 0.7858 - val_loss: 0.9133 - val_acc: 0.7609\n",
      "Epoch 139/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5793 - acc: 0.7838 - val_loss: 0.9080 - val_acc: 0.7602\n",
      "Epoch 140/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5778 - acc: 0.7824 - val_loss: 0.9130 - val_acc: 0.7622\n",
      "Epoch 141/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5777 - acc: 0.7835 - val_loss: 0.9164 - val_acc: 0.7602\n",
      "Epoch 142/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5769 - acc: 0.7806 - val_loss: 0.9343 - val_acc: 0.7615\n",
      "Epoch 143/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5765 - acc: 0.7847 - val_loss: 0.9268 - val_acc: 0.7629\n",
      "Epoch 144/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5763 - acc: 0.7849 - val_loss: 0.9376 - val_acc: 0.7622\n",
      "Epoch 145/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5765 - acc: 0.7849 - val_loss: 0.9369 - val_acc: 0.7615\n",
      "Epoch 146/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5751 - acc: 0.7832 - val_loss: 0.9400 - val_acc: 0.7622\n",
      "Epoch 147/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5749 - acc: 0.7849 - val_loss: 0.9459 - val_acc: 0.7629\n",
      "Epoch 148/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5748 - acc: 0.7852 - val_loss: 0.9302 - val_acc: 0.7622\n",
      "Epoch 149/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5736 - acc: 0.7861 - val_loss: 0.9452 - val_acc: 0.7635\n",
      "Epoch 150/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5748 - acc: 0.7826 - val_loss: 0.9209 - val_acc: 0.7629\n",
      "Epoch 151/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5753 - acc: 0.7869 - val_loss: 0.9400 - val_acc: 0.7629\n",
      "Epoch 152/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5736 - acc: 0.7844 - val_loss: 0.9468 - val_acc: 0.7629\n",
      "Epoch 153/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5728 - acc: 0.7858 - val_loss: 0.9541 - val_acc: 0.7629\n",
      "Epoch 154/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5733 - acc: 0.7852 - val_loss: 0.9556 - val_acc: 0.7629\n",
      "Epoch 155/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5722 - acc: 0.7867 - val_loss: 0.9523 - val_acc: 0.7629\n",
      "Epoch 156/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5722 - acc: 0.7852 - val_loss: 0.9731 - val_acc: 0.7615\n",
      "Epoch 157/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5719 - acc: 0.7869 - val_loss: 0.9781 - val_acc: 0.7622\n",
      "Epoch 158/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5717 - acc: 0.7867 - val_loss: 0.9820 - val_acc: 0.7629\n",
      "Epoch 159/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5708 - acc: 0.7867 - val_loss: 0.9791 - val_acc: 0.7629\n",
      "Epoch 160/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5713 - acc: 0.7852 - val_loss: 0.9943 - val_acc: 0.7622\n",
      "Epoch 161/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5704 - acc: 0.7855 - val_loss: 0.9870 - val_acc: 0.7629\n",
      "Epoch 162/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5705 - acc: 0.7858 - val_loss: 0.9904 - val_acc: 0.7622\n",
      "Epoch 163/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5695 - acc: 0.7855 - val_loss: 0.9861 - val_acc: 0.7629\n",
      "Epoch 164/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5697 - acc: 0.7864 - val_loss: 0.9875 - val_acc: 0.7629\n",
      "Epoch 165/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5696 - acc: 0.7852 - val_loss: 0.9844 - val_acc: 0.7629\n",
      "Epoch 166/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5694 - acc: 0.7858 - val_loss: 1.0110 - val_acc: 0.7615\n",
      "Epoch 167/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5691 - acc: 0.7867 - val_loss: 0.9892 - val_acc: 0.7622\n",
      "Epoch 168/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5681 - acc: 0.7869 - val_loss: 1.0075 - val_acc: 0.7635\n",
      "Epoch 169/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5684 - acc: 0.7861 - val_loss: 1.0246 - val_acc: 0.7642\n",
      "Epoch 170/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5687 - acc: 0.7858 - val_loss: 1.0368 - val_acc: 0.7615\n",
      "Epoch 171/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5683 - acc: 0.7867 - val_loss: 1.0220 - val_acc: 0.7615\n",
      "Epoch 172/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5670 - acc: 0.7864 - val_loss: 1.0137 - val_acc: 0.7629\n",
      "Epoch 173/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5669 - acc: 0.7872 - val_loss: 1.0197 - val_acc: 0.7629\n",
      "Epoch 174/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5677 - acc: 0.7861 - val_loss: 1.0191 - val_acc: 0.7629\n",
      "Epoch 175/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5661 - acc: 0.7869 - val_loss: 1.0122 - val_acc: 0.7615\n",
      "Epoch 176/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5661 - acc: 0.7892 - val_loss: 1.0227 - val_acc: 0.7629\n",
      "Epoch 177/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5653 - acc: 0.7884 - val_loss: 1.0248 - val_acc: 0.7622\n",
      "Epoch 178/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5657 - acc: 0.7881 - val_loss: 1.0204 - val_acc: 0.7629\n",
      "Epoch 179/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5655 - acc: 0.7867 - val_loss: 1.0309 - val_acc: 0.7622\n",
      "Epoch 180/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5686 - acc: 0.7864 - val_loss: 1.0221 - val_acc: 0.7615\n",
      "Epoch 181/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5657 - acc: 0.7875 - val_loss: 1.0296 - val_acc: 0.7629\n",
      "Epoch 182/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5653 - acc: 0.7878 - val_loss: 1.0383 - val_acc: 0.7629\n",
      "Epoch 183/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5642 - acc: 0.7872 - val_loss: 1.0546 - val_acc: 0.7629\n",
      "Epoch 184/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5641 - acc: 0.7861 - val_loss: 1.0418 - val_acc: 0.7642\n",
      "Epoch 185/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5654 - acc: 0.7895 - val_loss: 1.0513 - val_acc: 0.7622\n",
      "Epoch 186/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5637 - acc: 0.7835 - val_loss: 1.0579 - val_acc: 0.7629\n",
      "Epoch 187/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5637 - acc: 0.7881 - val_loss: 1.0379 - val_acc: 0.7629\n",
      "Epoch 188/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5629 - acc: 0.7878 - val_loss: 1.0516 - val_acc: 0.7629\n",
      "Epoch 189/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5630 - acc: 0.7898 - val_loss: 1.0549 - val_acc: 0.7622\n",
      "Epoch 190/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5632 - acc: 0.7889 - val_loss: 1.0574 - val_acc: 0.7635\n",
      "Epoch 191/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5623 - acc: 0.7867 - val_loss: 1.0485 - val_acc: 0.7629\n",
      "Epoch 192/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5639 - acc: 0.7915 - val_loss: 1.0648 - val_acc: 0.7622\n",
      "Epoch 193/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5618 - acc: 0.7861 - val_loss: 1.0728 - val_acc: 0.7622\n",
      "Epoch 194/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5618 - acc: 0.7869 - val_loss: 1.0657 - val_acc: 0.7635\n",
      "Epoch 195/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5630 - acc: 0.7864 - val_loss: 1.0772 - val_acc: 0.7635\n",
      "Epoch 196/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5619 - acc: 0.7887 - val_loss: 1.0698 - val_acc: 0.7629\n",
      "Epoch 197/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5618 - acc: 0.7858 - val_loss: 1.0746 - val_acc: 0.7622\n",
      "Epoch 198/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5613 - acc: 0.7858 - val_loss: 1.0787 - val_acc: 0.7635\n",
      "Epoch 199/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5605 - acc: 0.7861 - val_loss: 1.0956 - val_acc: 0.7615\n",
      "Epoch 200/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5613 - acc: 0.7867 - val_loss: 1.0892 - val_acc: 0.7622\n",
      "Epoch 201/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5597 - acc: 0.7887 - val_loss: 1.0755 - val_acc: 0.7629\n",
      "Epoch 202/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5613 - acc: 0.7861 - val_loss: 1.0705 - val_acc: 0.7629\n",
      "Epoch 203/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5590 - acc: 0.7875 - val_loss: 1.0775 - val_acc: 0.7629\n",
      "Epoch 204/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5602 - acc: 0.7901 - val_loss: 1.0676 - val_acc: 0.7629\n",
      "Epoch 205/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5595 - acc: 0.7892 - val_loss: 1.0935 - val_acc: 0.7635\n",
      "Epoch 206/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5588 - acc: 0.7847 - val_loss: 1.0809 - val_acc: 0.7629\n",
      "Epoch 207/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5599 - acc: 0.7878 - val_loss: 1.0981 - val_acc: 0.7622\n",
      "Epoch 208/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5582 - acc: 0.7875 - val_loss: 1.0745 - val_acc: 0.7622\n",
      "Epoch 209/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5587 - acc: 0.7875 - val_loss: 1.0767 - val_acc: 0.7635\n",
      "Epoch 210/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5588 - acc: 0.7872 - val_loss: 1.0835 - val_acc: 0.7629\n",
      "Epoch 211/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5581 - acc: 0.7861 - val_loss: 1.0983 - val_acc: 0.7629\n",
      "Epoch 212/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5580 - acc: 0.7855 - val_loss: 1.0962 - val_acc: 0.7622\n",
      "Epoch 213/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5579 - acc: 0.7872 - val_loss: 1.1059 - val_acc: 0.7635\n",
      "Epoch 214/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5582 - acc: 0.7869 - val_loss: 1.1062 - val_acc: 0.7629\n",
      "Epoch 215/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5572 - acc: 0.7884 - val_loss: 1.1111 - val_acc: 0.7642\n",
      "Epoch 216/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5569 - acc: 0.7872 - val_loss: 1.1092 - val_acc: 0.7615\n",
      "Epoch 217/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5575 - acc: 0.7889 - val_loss: 1.0931 - val_acc: 0.7642\n",
      "Epoch 218/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5565 - acc: 0.7861 - val_loss: 1.1138 - val_acc: 0.7642\n",
      "Epoch 219/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5571 - acc: 0.7910 - val_loss: 1.1055 - val_acc: 0.7635\n",
      "Epoch 220/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5558 - acc: 0.7872 - val_loss: 1.1174 - val_acc: 0.7622\n",
      "Epoch 221/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5567 - acc: 0.7887 - val_loss: 1.1082 - val_acc: 0.7642\n",
      "Epoch 222/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5561 - acc: 0.7864 - val_loss: 1.1389 - val_acc: 0.7629\n",
      "Epoch 223/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5568 - acc: 0.7901 - val_loss: 1.1198 - val_acc: 0.7635\n",
      "Epoch 224/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5549 - acc: 0.7884 - val_loss: 1.1159 - val_acc: 0.7622\n",
      "Epoch 225/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5553 - acc: 0.7892 - val_loss: 1.1223 - val_acc: 0.7629\n",
      "Epoch 226/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5546 - acc: 0.7895 - val_loss: 1.1256 - val_acc: 0.7615\n",
      "Epoch 227/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5546 - acc: 0.7892 - val_loss: 1.1227 - val_acc: 0.7642\n",
      "Epoch 228/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5547 - acc: 0.7881 - val_loss: 1.1299 - val_acc: 0.7642\n",
      "Epoch 229/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5540 - acc: 0.7878 - val_loss: 1.1267 - val_acc: 0.7629\n",
      "Epoch 230/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5551 - acc: 0.7872 - val_loss: 1.1350 - val_acc: 0.7609\n",
      "Epoch 231/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5538 - acc: 0.7884 - val_loss: 1.1264 - val_acc: 0.7642\n",
      "Epoch 232/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5537 - acc: 0.7869 - val_loss: 1.1451 - val_acc: 0.7629\n",
      "Epoch 233/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5535 - acc: 0.7912 - val_loss: 1.1316 - val_acc: 0.7642\n",
      "Epoch 234/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5536 - acc: 0.7884 - val_loss: 1.1348 - val_acc: 0.7615\n",
      "Epoch 235/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5527 - acc: 0.7904 - val_loss: 1.1456 - val_acc: 0.7629\n",
      "Epoch 236/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5530 - acc: 0.7884 - val_loss: 1.1234 - val_acc: 0.7629\n",
      "Epoch 237/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5530 - acc: 0.7889 - val_loss: 1.1281 - val_acc: 0.7635\n",
      "Epoch 238/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5530 - acc: 0.7901 - val_loss: 1.1459 - val_acc: 0.7629\n",
      "Epoch 239/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5524 - acc: 0.7889 - val_loss: 1.1341 - val_acc: 0.7615\n",
      "Epoch 240/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5524 - acc: 0.7875 - val_loss: 1.1347 - val_acc: 0.7622\n",
      "Epoch 241/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5523 - acc: 0.7912 - val_loss: 1.1314 - val_acc: 0.7642\n",
      "Epoch 242/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5519 - acc: 0.7881 - val_loss: 1.1532 - val_acc: 0.7602\n",
      "Epoch 243/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5511 - acc: 0.7881 - val_loss: 1.1297 - val_acc: 0.7629\n",
      "Epoch 244/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5510 - acc: 0.7878 - val_loss: 1.1501 - val_acc: 0.7615\n",
      "Epoch 245/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5508 - acc: 0.7887 - val_loss: 1.1392 - val_acc: 0.7622\n",
      "Epoch 246/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5513 - acc: 0.7889 - val_loss: 1.1318 - val_acc: 0.7622\n",
      "Epoch 247/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5505 - acc: 0.7901 - val_loss: 1.1424 - val_acc: 0.7615\n",
      "Epoch 248/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5502 - acc: 0.7892 - val_loss: 1.1421 - val_acc: 0.7622\n",
      "Epoch 249/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5506 - acc: 0.7892 - val_loss: 1.1341 - val_acc: 0.7635\n",
      "Epoch 250/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5495 - acc: 0.7915 - val_loss: 1.1502 - val_acc: 0.7615\n",
      "Epoch 251/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5497 - acc: 0.7884 - val_loss: 1.1586 - val_acc: 0.7629\n",
      "Epoch 252/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5502 - acc: 0.7864 - val_loss: 1.1416 - val_acc: 0.7642\n",
      "Epoch 253/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5495 - acc: 0.7872 - val_loss: 1.1480 - val_acc: 0.7602\n",
      "Epoch 254/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5488 - acc: 0.7864 - val_loss: 1.1577 - val_acc: 0.7602\n",
      "Epoch 255/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5494 - acc: 0.7881 - val_loss: 1.1597 - val_acc: 0.7622\n",
      "Epoch 256/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5488 - acc: 0.7898 - val_loss: 1.1513 - val_acc: 0.7635\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492/3492 [==============================] - 0s - loss: 0.5490 - acc: 0.7881 - val_loss: 1.1438 - val_acc: 0.7629\n",
      "Epoch 258/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5491 - acc: 0.7918 - val_loss: 1.1453 - val_acc: 0.7635\n",
      "Epoch 259/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5484 - acc: 0.7901 - val_loss: 1.1820 - val_acc: 0.7602\n",
      "Epoch 260/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5491 - acc: 0.7875 - val_loss: 1.1567 - val_acc: 0.7622\n",
      "Epoch 261/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5486 - acc: 0.7892 - val_loss: 1.1512 - val_acc: 0.7635\n",
      "Epoch 262/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5478 - acc: 0.7907 - val_loss: 1.1650 - val_acc: 0.7609\n",
      "Epoch 263/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5476 - acc: 0.7872 - val_loss: 1.1724 - val_acc: 0.7622\n",
      "Epoch 264/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5479 - acc: 0.7895 - val_loss: 1.1664 - val_acc: 0.7622\n",
      "Epoch 265/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5465 - acc: 0.7910 - val_loss: 1.1410 - val_acc: 0.7622\n",
      "Epoch 266/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5476 - acc: 0.7918 - val_loss: 1.1490 - val_acc: 0.7622\n",
      "Epoch 267/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5475 - acc: 0.7878 - val_loss: 1.1593 - val_acc: 0.7635\n",
      "Epoch 268/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5466 - acc: 0.7910 - val_loss: 1.1575 - val_acc: 0.7622\n",
      "Epoch 269/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5469 - acc: 0.7898 - val_loss: 1.1771 - val_acc: 0.7615\n",
      "Epoch 270/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5461 - acc: 0.7930 - val_loss: 1.1507 - val_acc: 0.7629\n",
      "Epoch 271/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5466 - acc: 0.7910 - val_loss: 1.1714 - val_acc: 0.7629\n",
      "Epoch 272/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5466 - acc: 0.7889 - val_loss: 1.1676 - val_acc: 0.7629\n",
      "Epoch 273/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5466 - acc: 0.7901 - val_loss: 1.1847 - val_acc: 0.7602\n",
      "Epoch 274/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5459 - acc: 0.7895 - val_loss: 1.1647 - val_acc: 0.7635\n",
      "Epoch 275/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5461 - acc: 0.7895 - val_loss: 1.1510 - val_acc: 0.7635\n",
      "Epoch 276/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5469 - acc: 0.7918 - val_loss: 1.1734 - val_acc: 0.7595\n",
      "Epoch 277/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5454 - acc: 0.7921 - val_loss: 1.1774 - val_acc: 0.7635\n",
      "Epoch 278/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5461 - acc: 0.7887 - val_loss: 1.1748 - val_acc: 0.7622\n",
      "Epoch 279/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5448 - acc: 0.7904 - val_loss: 1.1780 - val_acc: 0.7615\n",
      "Epoch 280/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5450 - acc: 0.7887 - val_loss: 1.1769 - val_acc: 0.7615\n",
      "Epoch 281/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5453 - acc: 0.7915 - val_loss: 1.1668 - val_acc: 0.7622\n",
      "Epoch 282/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5449 - acc: 0.7872 - val_loss: 1.1771 - val_acc: 0.7615\n",
      "Epoch 283/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5436 - acc: 0.7924 - val_loss: 1.1993 - val_acc: 0.7609\n",
      "Epoch 284/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5440 - acc: 0.7912 - val_loss: 1.1778 - val_acc: 0.7629\n",
      "Epoch 285/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5446 - acc: 0.7884 - val_loss: 1.1908 - val_acc: 0.7629\n",
      "Epoch 286/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5439 - acc: 0.7895 - val_loss: 1.1898 - val_acc: 0.7615\n",
      "Epoch 287/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5433 - acc: 0.7912 - val_loss: 1.1761 - val_acc: 0.7622\n",
      "Epoch 288/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5445 - acc: 0.7889 - val_loss: 1.1869 - val_acc: 0.7595\n",
      "Epoch 289/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5433 - acc: 0.7892 - val_loss: 1.1785 - val_acc: 0.7602\n",
      "Epoch 290/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5425 - acc: 0.7895 - val_loss: 1.1833 - val_acc: 0.7615\n",
      "Epoch 291/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5449 - acc: 0.7887 - val_loss: 1.1972 - val_acc: 0.7622\n",
      "Epoch 292/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5429 - acc: 0.7912 - val_loss: 1.2096 - val_acc: 0.7609\n",
      "Epoch 293/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5428 - acc: 0.7955 - val_loss: 1.1732 - val_acc: 0.7615\n",
      "Epoch 294/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5419 - acc: 0.7889 - val_loss: 1.2109 - val_acc: 0.7609\n",
      "Epoch 295/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5423 - acc: 0.7887 - val_loss: 1.1828 - val_acc: 0.7615\n",
      "Epoch 296/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5423 - acc: 0.7901 - val_loss: 1.1785 - val_acc: 0.7622\n",
      "Epoch 297/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5425 - acc: 0.7892 - val_loss: 1.1880 - val_acc: 0.7589\n",
      "Epoch 298/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5416 - acc: 0.7901 - val_loss: 1.1720 - val_acc: 0.7622\n",
      "Epoch 299/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5423 - acc: 0.7921 - val_loss: 1.2066 - val_acc: 0.7589\n",
      "Epoch 300/300\n",
      "3492/3492 [==============================] - 0s - loss: 0.5424 - acc: 0.7881 - val_loss: 1.1827 - val_acc: 0.7622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129365f28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "monitor = EarlyStopping(monitor='loss', min_delta=1e-3, patience=10, verbose=1, mode='auto')\n",
    "batch_size = 10\n",
    "epochs = 300\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[history_cb],verbose=1, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.7621910487641951\n"
     ]
    }
   ],
   "source": [
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0.0882  0.0033  0.      0.0494]\n",
      " [ 0.0047  0.0187  0.0127  0.0782]\n",
      " [ 0.0274  0.0053  0.0227  0.0354]\n",
      " [ 0.0013  0.004   0.016   0.6326]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Cm = confusion_matrix(y_eval,pred)\n",
    "C = np.sum(Cm)\n",
    "Cm = Cm/C\n",
    "print('Confusion Matrix:')\n",
    "print(np.array_str(Cm, precision=4, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1299cf1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valAcc = history_cb.val_acc\n",
    "valLoss = history_cb.val_loss\n",
    "epoch_it = np.arange(1,301)\n",
    "plt.subplot(121)\n",
    "plt.plot(epoch_it, valAcc)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.tight_layout()\n",
    "plt.subplot(122)\n",
    "plt.plot(epoch_it, valLoss)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlIiI5CQlKBERyUlKUCIikpP+P0cLU73hOxNaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d1bbf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ls = history_cb.losses\n",
    "Acc = history_cb.accs\n",
    "ntr = np.shape(x_train)[0]\n",
    "epochNum = []\n",
    "for i in range(33000):\n",
    "    epochNum.append(i*10/ntr)\n",
    "\n",
    "plt.subplot(121)\n",
    "matplotlib.pyplot.semilogy(epochNum, Acc)\n",
    "# plt.plot(epochNum, Acc)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(122)\n",
    "matplotlib.pyplot.semilogy(epochNum, Ls)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# plt.axis([0.3,3,0.96,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.63\n",
      "0 1 0.02\n",
      "0 2 0.00\n",
      "0 3 0.35\n",
      "---\n",
      "1 0 0.04\n",
      "1 1 0.16\n",
      "1 2 0.11\n",
      "1 3 0.68\n",
      "---\n",
      "2 0 0.30\n",
      "2 1 0.06\n",
      "2 2 0.25\n",
      "2 3 0.39\n",
      "---\n",
      "3 0 0.00\n",
      "3 1 0.01\n",
      "3 2 0.02\n",
      "3 3 0.97\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# print(Cm[0])\n",
    "nd = [None]*4\n",
    "for i,nd in enumerate (Cm):\n",
    "    for j in range (len(nd)):\n",
    "        \n",
    "        print(i,j,\"%0.2f\"%(nd[j]/np.sum(nd)))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
